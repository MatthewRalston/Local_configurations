This is an organizational file for my thesis document.


Notes:
Test RACE efficiency with tobacco acid pyrophosphatase?
Presence of 5' triphosphate suggests transcription rather than nucleolytic product


* Introduction

* Methods

* Results- Sequencing
** Why use RNA-sequencing?
** How do we use RNA-seq and evaluate the quality of data it produces?
*** Before the full experiment was done, a 'test' experiment was performed to assess replicate correlation,
*** the number of transcripts produced from the assembly, and also to assess the coverage.
** What did we learn about the quality of data it produced?
* Results- Coverage Analysis
** Why do we analyze the coverage from the sequencing?
*** We assess the coverage to benchmark our ability to achieve high depth in the presence of contaminating rRNA,
*** to assess our degree of multiplexing to achieve the requisite coverage of the experimental factors (4 times, 3 stresses)
*** with some degree of replication as well. Assessing the coverage from a small 'mini' experiment was critical for
*** evaluating the current sequencing approach. Past experiments suffered from both RNA instability and rRNA contamination
*** which results in low coverage overall, especially at the 5' and 3' ends of the transcripts, so it was important
*** to address the trend of coverage across the length of each gene.
** How do we address and assess the coverage?
*** One of the obstacles for this project was achieving the requisite depth. Our solution was to use
*** enrichment techniques to increase the proportion of RNA coming from interesting coding regions.
*** Additionally, we multiplexed in a way to get close to ~25M clusters per sample (2x75). This allowed us to be
*** tolerant of ribosomal sequences contaminating our data, even after enrichment. I assessed the coverage achieved
*** by performing a ribosomal RNA filtering step to eliminate the rRNA, and comparing the data amounst before and after
*** to produce a contamination percentage. I then was able to create profiles of coverage across the length of the genome
*** and across the length of each gene. By normalizing with respect to gene length, the coverage trends of each gene
*** could be summarized with boxplots, understanding the distribution of coverage at each percentile of gene length.
** What were the findings from the coverage analyses?
* Results- Assembly and related analyses
** Why use transcriptome assembly?
*** A transcriptome assembly has not been done for C. aceotbutylicum before.
*** The current state of knowledge about the transcriptome is the product of automated annotation, functional inferences,
*** older gene-specific studies (e.g. RACE-PCR), and modern sequencing techniques. For many non-model organisms,
*** gene assignments are based almost entirely on bioinformatic techniques. For this reason, high-throughput sequencing techniques
*** are desirable. High-depth sequencing with NGS technology has produced rapid increases in the amount of sequenced genomes
*** and characterized transcripts. Transcriptome assembly is a technique that leverages the depth of shotgun sequencing to identify
*** transcript boundaries and novel or low-abundance transcripts. Transcriptome asembly is framed as a problem with a graph theoretic
*** solution. Similar to genome assembly, the objective is to join growing contigs through overlap and sequence identity. Contig boundaries
*** are dictated by the depth of coverag at the ends of transcripts. Only high-depth coverage produces the number of reads required
*** to estimate these boundaries, and typically > 10x coverage is required for a single point snapshot of the transcriptome.
*** Additionaly, the factors of stress and time influence the configuration of the transcriptome. With these considerations, snapshots
*** from different conditions can be made to capture changes in transcriptional start sites and accuracy of assembly from low-abundance
*** transcripts. We use this sequencing technique and the de-Bruijn graph assembler 'Trinity' to create transcriptome assemblies
*** for assessment.
** How do we use transcriptome assembly and evaluate its quality?
*** Transcriptome assembly has inherited some metrics from genome assembly (N50, etc.) and has acquired some newer metrics from
*** bioinformatics. Traditional metrics include the number of transcripts, min, max, and avg transcript size, N50 (transcript size in which
*** 50% of all assembled bases is from larger transcripts), number of singleton reads, and others.
*** I have produced a forked version of 'transrate' that reports singleton reads, realignment statistics, and other statistics.
*** Additional metrics include ORF number, reciprocal best blast hits, ____, and others.
*** Many of the modern techniques are based on the agreement between the assembled transcriptome and a reference proteom (an automated annotation, for example)
*** These techniques will be discussed in the reannotation section.
*** 
** What are the findings from the assembly assessment?
** Any new genes?
** Any transcription start sites?
* Results- Reannotation
** Why use transcriptome annotation?
*** The current proteome annotation simply consists of predicted CDSes based on annotation of the CAC genome, and not the transcriptome.
*** Agreement with an older assembly may be a positive indicator in some circumstances and a negative indicator in others.
*** For example, if a new assembly produces a number of previously unannotated transcripts,
*** this is most likely a reflection of the limitation of older automated pipelines, than a problem with the new assembly. Similarly, if the new assembly's
*** annotation fails to produce some of the annotated proteins, this may not necessarily be a problem: these could be false positives from the
*** previous annotation.

** How do we use reannotation and evaluate it's quality?
*** In practice, I have used my fork of 'transrate' to provide some of the basic metrics.
*** The princpal effort of reannotation is comparing the new annotation to the old annotation.
*** Proteins were predicted in the old annotation by the following:
**** extract all ORFs
**** BLAST and find closest match
**** if no match:
***** accept if the ORF is greater than 400 residues
***** or if the protein displays a C. acetobutylicum dicodon usage
*** In this iteration, several techniques will be used:
**** Locate all ORFs with Transdecoder
**** blastx protein databases (SwissProt, Uniprot, Uniref90) against transcripts
**** blastp predicted proteins against SwissProt, and Uniref90
**** Run HMMER to identify protein domains
**** Run signalP to predict signal peptides
**** Run tmHMM to predict transmembrane regions
**** Run RNAMMer to predict rRNAs, tRNAs, sRNAs
*** Summarization of reannotation results
**** Novel proteins
***** Proteins from this step that are not reassigned to CAC proteins will be described as novel
***** Novel proteins will be subsequent to case-by-case reanalysis to see if BLAST simply failed
***** to identify the correct CAC protein. Else, the reciprocal best blast and related proteins
***** will be used to infer function.
**** 'Deprecated' proteins
***** Proteins from the original annotation that do not have a corresponding transcript in the new annotation
***** Will also be subjected to reanalysis for BLAST failures. Otherwise, the protein will be flagged
***** as suspect.
*** CAC Superoperon???
*** Comparative analysis of final proteome
**** A comparative analysis can be done, comparing the C. ac proteome in a pairwise manner to other known proteomes
**** A taxonomic analysis of reciprocal best blast hits can be performed to show the taxonomic relationships of the new annotation
**** to the reciprocal best-blast protein hits, and the RBB hits with experimental evidence.
*** COG grouping
** What are the findings from the reannotation?
* Results- Differential Expression
** Why look at differential expression (and other analyses: PCA, etc) [INTRODUCTION]
*** What is differential expression analysis?
**** Differential expression describes the response of a biological system to stimulation
**** When stimulated, gene expression levels change, providing insight into the
**** organization of the molecular system, hidden behind the dynamics of the change.
**** For example, a gene whose response peaks at an early time
**** may be a transcription factor for a gene whose response peaks afterwards.
*** What were our experimental conditions of interest?
**** In this experiment, I perturbed these systems by increasing the concentration
**** of small molecule metabolites to stressful levels, and sampling at various time points
*** Why did I investigate these factors?
**** On the simplest level, a differential expression analysis allows us to identify genes
**** that respond to stress. On a deeper level, this analysis allows us to identify putative
**** transcripts that are also stress responsive. (if the transcripts were merely artifacts
**** of library preparation and not true findings, we would expect their levels to be
**** uniformly distributed and independent of stress). 
**** Secondly, the factor of time allows us to identify the trend of a gene's response over time
**** dividing the stress responsive genes into categories/clusters. Novel genes found through assembly
**** may be regulated by similar mechanisms to the genes in their cluster. Their role in the stress response
**** perhaps as positive or negative regulators of the stress response regulators may be inferred from their
**** trend of the gene over time.
**** Thirdly, clustering of these genes allows us to identify motifs upstream of the gene in a similar cluster. A tight clustering
**** is indicative of similar regulation, adding directed edges to the current understanding of
**** the stress response network.
**** SUMMARY: I hypothesize that there are novel stress response regulators that have similar
**** expression profiles to known stress responsive genes.
**** By using gene expression clustering, I hope to identify the response regulators of each
**** cluster and novel gene.
*** 
** How do we evaluate patterns of differential expression [METHODS/RESULTS]
*** What is principal components analysis and what methods are used?
**** Principal components analysis is a fundamental part of the analysis of large
**** datasets. The dataset takes the shape of a NxM expression matrix with large N (> 1000), the number of genes.
**** Datasets of such size are difficult to explore graphically, especially if M is also relatively large.
**** In the case of differential expression analysis, the number of conditions is a function of the number of experimental
**** factors. For this reason, PCA, is a central part of 'factor analysis.' The objective of PCA is to reduce the dimensionality
**** of the dataset to ideally a MxM dataset, since M << N. Such a dataset describes the behavior of each condition. The reduced
**** dataset consists of a condition's coordinates in terms of the dataset's principal components. By focusing on a few principal
**** components at a time, this allows us to visualize each of the M conditions in 2 or 3 dimensions at a time. Combining this visualization
**** with the condition metadata allows us to view spatial patterns in the locations of the conditions in space. Ideally, conditions
**** that share a similar factor (e.g. stress or time) would have similar localization in the space spanned by the principal components.
**** Practically, this is done by using computer-aided singular value decomposition to produce a matrix of the conditions
**** in terms of the principal components. By simply visualizing the rows/conditions, selecting 2 or 3 components at a time we can identify
**** clustering of the conditions by the factors.
*** What is differential expression analysis and what methods are used?
**** Differential expression analysis is usually performed on a NxM count matrix
**** for N genes and M samples. First, the data must be normalized by library size
**** (not to be confused with statistical normalization, where mean equals 0 etc.)
**** Next, there is an optional regularization step, which uses a model to fit variance estimates
**** and adjust the data (increasing or decreasing the variance for some genes.)
**** Finally, a statistical hypothesis test is used, with the null hypothesis of
**** no differential expression between the two conditions.
**** The results from such analysis include p-values and log fold changes of the comparison
**** for each of N genes, normalized/regularized expression values and variance estimates
**** These results can be visualized by a number of packaged visualizations, can be customized to some degree
**** with a programming language such as python's matplotlib or R's integrated/lattice/ggplot systems.
**** However, with the size of the data and the number of comparisons, interactive visualizations are most useful.
*** What is cluster analysis and what methods are used?
**** Cluster analysis is the use of unsupervized machine learning techniques to partition the data
**** specifically, the genes, into groups by related behaviors. Typical examples of clustering techniques include
**** Hierarchical clustering and k-means. These algorithms partition the data according to a distance metric, relying
**** on the nature of the data to provide separation and membership.
**** Several cluster methods, distance methods, and algorithms are available to cluster data. Hierarchical clustering
**** is useful and very well reflects the structure of the data, prone to identifying singleton clusters.
**** Iterative k-means/medioids methods are useful and elegant, but rely on the knowledge of the correct number of clusters
**** 'k' ahead of time. A newer algorithm known as dbscan can produce high quality results, but is sensitive to a
**** distance parameter epsilon. A newer version of this algorithm known as optics requires only a minimum number of objects/genes
**** per cluster.
**** Clustering methods are most meaningful when using a subset of the initial dataset (e.g. differentially expressed only)
**** and perhaps after removing singleton clusters through hierarchical analysis.
**** Clustering results can be visualized as dendrograms, on a 2D PC plot, or through variations on a circular plot.
**** Clustering results may be evaluated in a few ways, where A is clustering accuracy:
**** First, what is the agreement between points within a cluster? As A approaches 100%, this agreement metric (inverse of distance) should increase
**** Second, what is the agreement between points outside of a cluster? As A approaches 100%, this agrement metric should decrease.
**** In summary, the metrics of intra and inter-cluster similarity describe the efficiency of clustering.
**** An excellent cluster could also serve as the basis for a machine learning classifier.
*** What is gene ontology analysis and how is it used?
**** Gene ontologies are controlled vocabularies that describe biological processes, molecular functions, and cellular compartments
**** of protein products. These vocabularies are useful in understanding the role of a set of genes en masse: e.g. after a cluster
**** analysis. Gene ontologies are maintained through the GO consortium and are accessible through several tools. While many tools
**** exist for such analyses, many are optimized for model organisms and are not available for lesser organism. This is likely due
**** to the complex networked hierarchy of GO terminologies. While the databases themselves are not incredibly massive, it is rare to
**** find a resource which has the terminologies linked to the gene identifiers of non-model organisms. Therefore, I will be using
**** the resource known as 'DAVID' to provide GO annotations. In practice, a list of gene names is supplied to the DAVID web portal.
**** The criterion for selection of the genes of this list (e.g. differential expression, cluster membership, etc.) I denote as C.
**** The list is then analyzed for enrichment of categories of GO terms using a hypergeometric test. Finally, the independence
**** of the GO category and the criterion C is assessed with Fisher's exact test.

** What do we observe from the patterns of differential expression?
*** X genes in total were differentially expressed across the conditions
*** The statistical criterion (model, p and log fold change thresholds) are
*** Y genes were upregulated at some point
*** Z genes were downregulated at some point
*** Time series analysis
**** What genes are differentially expressed in the normal condition only at later time points?
**** Are these same genes and processes enriched in the normal condition at later time points?
**** We can analyze this by comparing a later time point to an earlier time point (t vs t-1)
**** or by comparing a later time point to the first time point(tx vs t1)
*** GO enrichment
**** In butanol stress, ______ processes were upregulated
**** In butyrate stress, _____ processes were upregulated
**** Under both conditions, _______ processes were upregulated
**** In butanol stress, _____ processes were downregulated
**** In butyrate stress, ______ processes were downregulated
**** Under both conditions, ______ processes were downregulated.
**** The most commonly enriched processes were ______, _______, and _______
*** Principal components analysis
**** The objective of principal components analysis is to provide dimensionality reduction
**** With dimensionality reduction, we can observe clusters of related samples in the lower
**** space. Observing clusters of related samples allows us to verify that the underlying
**** structure in the data represents the experimental design
**** 
*** Coexpression clustering
**** Uhhhh
*** cis-RNA
**** Differential expression for cis rnas was obtained by:
***** Performing assembly
***** Creating a gtf file of the novel cis rna transcripts
***** Acquiring read counts and performing differential expression
**** We observe that....
* Discussion

* Conclusion
